{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NBA Halftime Prediction Model\n",
    "\n",
    "Can we predict whether the home team wins using only first-half data?\n",
    "\n",
    "**Features:**\n",
    "- Halftime scores and score differential\n",
    "- Q1 scores and score differential\n",
    "- Scoring momentum (Q2 vs Q1 scoring change)\n",
    "- FG% by shot zone (paint, midrange, three) for each team\n",
    "- Shot distribution by zone for each team\n",
    "\n",
    "**Models:** Logistic Regression, Random Forest\n",
    "\n",
    "**Data:** ~913,000 play-by-play rows across 1,830 NBA games (2024-25 + partial 2025-26)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    dbname=os.getenv('DB_NAME'),\n",
    "    user=os.getenv('DB_USER'),\n",
    "    host=os.getenv('DB_HOST'),\n",
    "    password=os.getenv('DB_PASSWORD'),\n",
    "    port=os.getenv('DB_PORT')\n",
    ")\n",
    "\n",
    "df = pd.read_sql('SELECT * FROM nba_data', conn)\n",
    "conn.close()\n",
    "\n",
    "print(f'Rows: {len(df):,}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Target Variable\n",
    "\n",
    "Determine the winner of each game from the final scores (last row per game)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_scores = df.groupby('gameid')[['scorehome', 'scoreaway']].last()\n",
    "final_scores['home_win'] = (final_scores['scorehome'] > final_scores['scoreaway']).astype(int)\n",
    "\n",
    "print(f\"Games: {len(final_scores)}\")\n",
    "print(final_scores['home_win'].value_counts())\n",
    "final_scores.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a. Halftime Scores and Differential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_half = df[df['period'] <= 2]\n",
    "\n",
    "lead = first_half.groupby('gameid')[['scorehome', 'scoreaway']].last()\n",
    "lead['halftime_diff'] = lead['scorehome'] - lead['scoreaway']\n",
    "lead.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b. Q1 Scores and Differential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_quarter = df[df['period'] <= 1].groupby('gameid')[['scorehome', 'scoreaway']].last()\n",
    "first_quarter['Q1Difference'] = first_quarter['scorehome'] - first_quarter['scoreaway']\n",
    "\n",
    "features = lead.join(first_quarter, lsuffix='_half', rsuffix='_q1')\n",
    "features.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3c. Scoring Momentum\n",
    "\n",
    "Momentum = Q2 scoring - Q1 scoring. Positive means the team scored more in Q2 than Q1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_momentum = (features['scorehome_half'] - features['scorehome_q1']) - features['scorehome_q1']\n",
    "away_momentum = (features['scoreaway_half'] - features['scoreaway_q1']) - features['scoreaway_q1']\n",
    "\n",
    "features['home_momentum'] = home_momentum\n",
    "features['away_momentum'] = away_momentum\n",
    "features.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3d. Shot Zones\n",
    "\n",
    "Classify first-half shots into three zones based on distance:\n",
    "- **Paint**: 0-8 ft\n",
    "- **Midrange**: 8-23.75 ft\n",
    "- **Three**: 23.75+ ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_half_shots = first_half[first_half['isfieldgoal'] == 1].copy()\n",
    "first_half_shots['zone'] = pd.cut(\n",
    "    first_half_shots['shotdistance'],\n",
    "    bins=[0, 8, 23.75, 100],\n",
    "    labels=['paint', 'midrange', 'three']\n",
    ")\n",
    "first_half_shots['made'] = (first_half_shots['shotresult'] == 'Made').astype(int)\n",
    "\n",
    "print(f\"First-half shot attempts: {len(first_half_shots):,}\")\n",
    "first_half_shots[['gameid', 'shotdistance', 'zone', 'shotresult']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3e. FG% by Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_pct = first_half_shots.groupby(['gameid', 'location', 'zone'], observed=True)['made'].mean()\n",
    "fg_pct_flat = fg_pct.unstack(['location', 'zone'])\n",
    "fg_pct_flat.columns = [\n",
    "    f\"{'home' if loc == 'h' else 'away'}_fg_{zone}\"\n",
    "    for loc, zone in fg_pct_flat.columns\n",
    "]\n",
    "fg_pct_flat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3f. Shot Distribution by Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shot_dist = first_half_shots.groupby(['gameid', 'location'], observed=True)['zone'].value_counts(normalize=True)\n",
    "shot_dist_flat = shot_dist.unstack(['location', 'zone'])\n",
    "shot_dist_flat.columns = [\n",
    "    f\"{'home' if loc == 'h' else 'away'}_dist_{zone}\"\n",
    "    for loc, zone in shot_dist_flat.columns\n",
    "]\n",
    "shot_dist_flat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = features.join(fg_pct_flat).join(shot_dist_flat).join(final_scores['home_win'])\n",
    "final_df = final_df.fillna(0)\n",
    "\n",
    "print(f\"Games: {len(final_df)}, Features: {len(final_df.columns) - 1}\")\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = final_df.drop('home_win', axis=1)\n",
    "y = final_df['home_win']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f\"Train: {len(X_train)}, Test: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Train accuracy: {lr_model.score(X_train_scaled, y_train):.3f}\")\n",
    "print(f\"Test accuracy: {lr_model.score(X_test_scaled, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Train accuracy: {rf_model.score(X_train, y_train):.3f}\")\n",
    "print(f\"Test accuracy: {rf_model.score(X_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Logistic Regression\n",
    "cm_lr = confusion_matrix(y_test, lr_model.predict(X_test_scaled))\n",
    "ConfusionMatrixDisplay(cm_lr, display_labels=['Away Win', 'Home Win']).plot(ax=axes[0], cmap='Blues')\n",
    "axes[0].set_title('Logistic Regression')\n",
    "\n",
    "# Random Forest\n",
    "cm_rf = confusion_matrix(y_test, rf_model.predict(X_test))\n",
    "ConfusionMatrixDisplay(cm_rf, display_labels=['Away Win', 'Home Win']).plot(ax=axes[1], cmap='Greens')\n",
    "axes[1].set_title('Random Forest')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = pd.Series(rf_model.feature_importances_, index=X.columns).sort_values(ascending=True)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "importances.plot(kind='barh')\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature Importance (Random Forest)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Halftime Differential vs Win Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bin halftime differentials and calculate actual win rate per bin\n",
    "final_df['diff_bin'] = pd.cut(final_df['halftime_diff'], bins=20)\n",
    "win_rate = final_df.groupby('diff_bin', observed=True)['home_win'].mean()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "win_rate.plot(kind='bar', color='steelblue')\n",
    "plt.axhline(y=0.5, color='red', linestyle='--', label='50% win rate')\n",
    "plt.xlabel('Halftime Differential (Home - Away)')\n",
    "plt.ylabel('Home Win Rate')\n",
    "plt.title('Halftime Lead vs Actual Home Win Rate')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Summary\n\n| Model | Train Accuracy | Test Accuracy |\n|-------|---------------|---------------|\n| Logistic Regression | 73.0% | 72.7% |\n| Random Forest (max_depth=5) | 78.8% | 71.6% |\n\n**Key Findings:**\n- Halftime score differential is the dominant predictor (~28% importance)\n- Raw halftime scores (home and away) are the next most important features (~13% each)\n- Q1 differential adds meaningful signal (~9%)\n- Shot location features (FG% and distribution by zone) contribute 1-3% each\n- Both models converge at ~72% test accuracy, suggesting this is roughly the ceiling for halftime-only prediction\n- The halftime lead vs win rate chart shows a clear S-curve: teams up 15+ at halftime win ~90%+ of the time"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}